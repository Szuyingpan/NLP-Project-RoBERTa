{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Szuyingpan/NLP-Project-RoBERTa/blob/main/Copy_of_NLP_Sentiment_Analysis_RoBERTa_Model_(2)_(1).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "22a8e041"
      },
      "outputs": [],
      "source": [],
      "id": "22a8e041"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "236a57b0"
      },
      "outputs": [],
      "source": [
        "#https://huggingface.co/docs/transformers/model_doc/roberta"
      ],
      "id": "236a57b0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JJhnIA1lyp_L"
      },
      "outputs": [],
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "id": "JJhnIA1lyp_L"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2d0751c"
      },
      "source": [
        "## 1. Important library"
      ],
      "id": "c2d0751c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73fb5587"
      },
      "outputs": [],
      "source": [
        "#!pip install transformers==3.0.2"
      ],
      "id": "73fb5587"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8qDXRi5gJWwK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "308eb7b6-094b-4f3e-e937-0ad1a29af656"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "8qDXRi5gJWwK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4999121f"
      },
      "outputs": [],
      "source": [
        "# Importing the libraries needed\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import seaborn as sns\n",
        "import transformers\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from transformers import RobertaModel, RobertaTokenizer\n",
        "import logging\n",
        "logging.basicConfig(level=logging.ERROR)"
      ],
      "id": "4999121f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cO9wldlSdkb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b9ccbd0d-cde5-4a8f-cd5c-59ac5d2b6019"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ],
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f'Using device: {device}')"
      ],
      "id": "6cO9wldlSdkb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5ef35276"
      },
      "outputs": [],
      "source": [
        "# Setting up the device for GPU usage\n",
        "\n",
        "from torch import cuda\n",
        "device = 'cuda' if cuda.is_available() else 'cpu'"
      ],
      "id": "5ef35276"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eddbd8a"
      },
      "source": [
        "## 2. Important dataset"
      ],
      "id": "7eddbd8a"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Probability threshold to read a line\n",
        "probability_threshold = 0.01\n",
        "\n",
        "# Initialize lists to store the separated sentiments and phrases\n",
        "sentiments = []\n",
        "phrases = []\n",
        "\n",
        "# Open the file and read line by line\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/train.ft.txt', 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        # Randomly decide whether to process this line\n",
        "        if random.random() <= probability_threshold:\n",
        "            # Extract sentiment and phrase using regex\n",
        "            match = re.match(r'(__label__\\d) (.*)', line)\n",
        "            \"label_1 means negative (0); label_2 means positive(1)\"\n",
        "            if match:\n",
        "                sentiments.append(match.group(1).replace('__label__1', '0').replace('__label__2', '1'))\n",
        "                phrases.append(match.group(2))\n",
        "\n",
        "# Create a DataFrame from the lists\n",
        "train = pd.DataFrame({\n",
        "    'sentiment': sentiments,\n",
        "    'phrase': phrases\n",
        "})\n",
        "\n",
        "# Check the first few rows to ensure it's loaded correctly\n",
        "print(train.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Im-C9m1yxQ0H",
        "outputId": "64764892-77f6-46da-fa5b-222f686e65eb"
      },
      "id": "Im-C9m1yxQ0H",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sentiment                                             phrase\n",
            "0         0  Works, but not as advertised: I bought one of ...\n",
            "1         1  Worth the wait!: JMM has never released a bad ...\n",
            "2         0  Molly Myers: Molly Myers, in her review of \"My...\n",
            "3         1  Intriguing story: While I don't consider it th...\n",
            "4         0  Obviously, not Adam Sandler's best: An accepta...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07194821",
        "outputId": "32d055f1-1b89-4ca6-878b-104e11a26354"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(35738, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 157
        }
      ],
      "source": [
        "train.shape"
      ],
      "id": "07194821"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "1ae66a64",
        "outputId": "de2ee0ac-5e0c-4315-8ad3-c4ace47f1d1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  sentiment                                             phrase\n",
              "0         0  Works, but not as advertised: I bought one of ...\n",
              "1         1  Worth the wait!: JMM has never released a bad ...\n",
              "2         0  Molly Myers: Molly Myers, in her review of \"My...\n",
              "3         1  Intriguing story: While I don't consider it th...\n",
              "4         0  Obviously, not Adam Sandler's best: An accepta..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-3ec115e7-6765-4506-a06b-90d055708129\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Works, but not as advertised: I bought one of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Worth the wait!: JMM has never released a bad ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>Molly Myers: Molly Myers, in her review of \"My...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Intriguing story: While I don't consider it th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Obviously, not Adam Sandler's best: An accepta...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3ec115e7-6765-4506-a06b-90d055708129')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-3ec115e7-6765-4506-a06b-90d055708129 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-3ec115e7-6765-4506-a06b-90d055708129');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8bd30345-2746-4f41-b8e0-ef21b90c678e\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8bd30345-2746-4f41-b8e0-ef21b90c678e')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8bd30345-2746-4f41-b8e0-ef21b90c678e button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "train",
              "summary": "{\n  \"name\": \"train\",\n  \"rows\": 35738,\n  \"fields\": [\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phrase\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 35738,\n        \"samples\": [\n          \"OH MY GOD!!!!!!!!!: AAAAAAAGH!!!!!.It haunts me in my sleep. Little strange people dorky girl.I wish I could put it in my microwave and bake it. AAAAAAAGH!!!!! I won't say another word.\",\n          \"McCaffrey, \\\"Smooth & Tropic\\\": Extremely original album! Lots of variety. A very \\\"international\\\", world album. Each track is unique.\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 158
        }
      ],
      "source": [
        "train.head()"
      ],
      "id": "1ae66a64"
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "train.groupby('sentiment').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "Oigq0UZD9HaH",
        "outputId": "c54ae7e9-5a83-4e68-a7ab-0b0e367720f5"
      },
      "id": "Oigq0UZD9HaH"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cdeb9afb",
        "outputId": "ea16d3c7-b979-4f2f-fa92-fa5b283e1060"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '1'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 160
        }
      ],
      "source": [
        "# Again 0 stands for negative, 1 means positive\n",
        "train['sentiment'].unique()"
      ],
      "id": "cdeb9afb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "96VEGVYl_Q9c",
        "outputId": "e19ff31a-b986-4949-8a8f-512960d60690"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        0\n",
            "1        1\n",
            "2        0\n",
            "3        1\n",
            "4        0\n",
            "        ..\n",
            "35733    1\n",
            "35734    0\n",
            "35735    1\n",
            "35736    1\n",
            "35737    1\n",
            "Name: sentiment, Length: 35738, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# change target data type to float\n",
        "print(train['sentiment'].astype(int))"
      ],
      "id": "96VEGVYl_Q9c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61f49cd4",
        "scrolled": true,
        "outputId": "d7d94302-f3da-4e3f-ccfa-a30955954b97"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    17914\n",
              "0    17824\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 162
        }
      ],
      "source": [
        "train['sentiment'].value_counts()"
      ],
      "id": "61f49cd4"
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import random\n",
        "import pandas as pd\n",
        "\n",
        "# Probability threshold to read a line\n",
        "probability_threshold = 0.01\n",
        "\n",
        "# Initialize lists to store the separated sentiments and phrases\n",
        "sentiments = []\n",
        "phrases = []\n",
        "\n",
        "# Open the file and read line by line\n",
        "with open('/content/drive/MyDrive/Colab Notebooks/test.ft.txt', 'r', encoding='utf-8') as file:\n",
        "    for line in file:\n",
        "        # Randomly decide whether to process this line\n",
        "        if random.random() <= probability_threshold:\n",
        "            # Extract sentiment and phrase using regex\n",
        "            match = re.match(r'(__label__\\d) (.*)', line)\n",
        "            \"label_1 means negative (0); label_2 means positive(1)\"\n",
        "            if match:\n",
        "                sentiments.append(match.group(1).replace('__label__1', '0').replace('__label__2', '1'))\n",
        "                phrases.append(match.group(2))\n",
        "\n",
        "# Create a DataFrame from the lists\n",
        "test = pd.DataFrame({\n",
        "    'sentiment': sentiments,\n",
        "    'phrase': phrases\n",
        "})\n",
        "\n",
        "# Check the first few rows to ensure it's loaded correctly\n",
        "print(test.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFwdGk7uyYKl",
        "outputId": "26f88240-4dfa-4f89-b29b-bb25276120b5"
      },
      "id": "TFwdGk7uyYKl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  sentiment                                             phrase\n",
            "0         0  ZERO stars... OMG I can't believe I even bothe...\n",
            "1         1  Chilbirth Education Video: Great videos!!!! I'...\n",
            "2         1  Fahrenheit 451: I read this book as a teenager...\n",
            "3         0  Warning. I HIGHLY don't recommend this set!: Y...\n",
            "4         0  Great movie butt o grainy on blueray: I like a...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e005f7a9",
        "outputId": "f3b5fefa-52ab-4fba-e15d-68ad218fa86c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3880, 2)"
            ]
          },
          "metadata": {},
          "execution_count": 164
        }
      ],
      "source": [
        "test.shape"
      ],
      "id": "e005f7a9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "3395102e",
        "outputId": "7cfe2093-4a8b-4718-e487-019a47e8c0a6"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "  sentiment                                             phrase\n",
              "0         0  ZERO stars... OMG I can't believe I even bothe...\n",
              "1         1  Chilbirth Education Video: Great videos!!!! I'...\n",
              "2         1  Fahrenheit 451: I read this book as a teenager...\n",
              "3         0  Warning. I HIGHLY don't recommend this set!: Y...\n",
              "4         0  Great movie butt o grainy on blueray: I like a..."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-31b34304-13c5-4350-9f36-a41e6ddd420a\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentiment</th>\n",
              "      <th>phrase</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>ZERO stars... OMG I can't believe I even bothe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>Chilbirth Education Video: Great videos!!!! I'...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>Fahrenheit 451: I read this book as a teenager...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>Warning. I HIGHLY don't recommend this set!: Y...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>Great movie butt o grainy on blueray: I like a...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-31b34304-13c5-4350-9f36-a41e6ddd420a')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-31b34304-13c5-4350-9f36-a41e6ddd420a button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-31b34304-13c5-4350-9f36-a41e6ddd420a');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-8f4b48ec-d7fe-4be4-b096-2ed9bd672db9\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-8f4b48ec-d7fe-4be4-b096-2ed9bd672db9')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-8f4b48ec-d7fe-4be4-b096-2ed9bd672db9 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "test",
              "summary": "{\n  \"name\": \"test\",\n  \"rows\": 3880,\n  \"fields\": [\n    {\n      \"column\": \"sentiment\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"1\",\n          \"0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"phrase\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3880,\n        \"samples\": [\n          \"he just doesn't have the voice for it: the opening track is splendid, but don't be taken in - listen to a few more before you buy. the problem with this collection of covers from the 30s and 40s is that ferry just can't live up to the great singing legends who did them first time around. bryan ferry has always been seen as a bit of a crooner, but that's because he looks the part, and all of his songs were carefully crafted (or in the case of earlier cover albums completely reworked) to accommodate his rather strange and limited vocal range.\",\n          \"How in the world did this band ever slip through the cracks?: I bought this CD a few months ago based solely on reviews - never heard the music before (except \\\"Love will Tear Us Apart\\\") - that they were supposed to sound alot like New Order. After the first listen I determined yeah, they do sound a little like New Order - except better and immediatley became my \\\"most treasured\\\" CD. These guys were so far ahead of thier time (probably the only reason they never got any recognition in 1978-1980) the material still sounds fresher than 90% of the stuff released in the past 4 years. I haven't heard any of their other CDs yet, and wonder how \\\"Closer\\\" and \\\"Unknown Pleasures\\\" stacks up musically to \\\"Substance\\\". We'll see ...\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 165
        }
      ],
      "source": [
        "test.head()"
      ],
      "id": "3395102e"
    },
    {
      "source": [
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "test.groupby('sentiment').size().plot(kind='barh', color=sns.palettes.mpl_palette('Dark2'))\n",
        "plt.gca().spines[['top', 'right',]].set_visible(False)"
      ],
      "cell_type": "code",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 430
        },
        "id": "rfK8I4aN9ARS",
        "outputId": "a1f962a2-0c60-4d9d-bb49-2c4d6ae7b5bd"
      },
      "id": "rfK8I4aN9ARS"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7db0503e",
        "outputId": "ce24d1f7-b88b-4025-813c-7e65e18020b4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '1'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 166
        }
      ],
      "source": [
        "test['sentiment'].unique()"
      ],
      "id": "7db0503e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i04aexPE--Jn",
        "outputId": "32aaebf1-c36b-4b95-8f70-2a12fdf8bfd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0       0\n",
            "1       1\n",
            "2       1\n",
            "3       0\n",
            "4       0\n",
            "       ..\n",
            "3875    0\n",
            "3876    1\n",
            "3877    0\n",
            "3878    1\n",
            "3879    0\n",
            "Name: sentiment, Length: 3880, dtype: int64\n"
          ]
        }
      ],
      "source": [
        "print(test['sentiment'].astype(int))"
      ],
      "id": "i04aexPE--Jn"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8SxZUq5Cu0mH",
        "outputId": "59418297-9084-4bea-a900-f71593f63be3"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    2001\n",
              "1    1879\n",
              "Name: sentiment, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ],
      "source": [
        "test['sentiment'].value_counts()"
      ],
      "id": "8SxZUq5Cu0mH"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3e00e849"
      },
      "source": [
        "## 3. Preparing the Dataset and Dataloader"
      ],
      "id": "3e00e849"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UvEkM0KrW-XK"
      },
      "source": [
        "This code defines a custom dataset class named SentimentData, intended for sentiment analysis tasks. It is designed to be used with PyTorch's Dataset interface, which requires implementing the __init__, __len__, and __getitem__ methods. Here's a quick breakdown:\n",
        "\n",
        "Initialization (__init__ method): The constructor takes three arguments:\n",
        "\n",
        "dataframe: A Pandas DataFrame containing the dataset. The dataframe is expected to have at least two columns: one for the text data (phrase) and another for the sentiment labels (sentiment).\n",
        "tokenizer: A tokenizer that is used to convert text into a format suitable for model training (token IDs, masks, etc.). This tokenizer is typically pre-trained (e.g., part of a BERT or RoBERTa model).\n",
        "max_len: The maximum length of the tokenized sequences. If not specified, a default value MAX_LEN is used. This is to ensure uniform sequence lengths for batching purposes.\n",
        "Length (__len__ method): This method returns the number of items in the dataset (i.e., the number of rows in the dataframe).\n",
        "\n",
        "Get Item (__getitem__ method): This method retrieves a single data point from the dataset. It takes an index and returns a dictionary containing the tokenized text, its attention mask, token type ids (if applicable), and the target label. The process is as follows:\n",
        "\n",
        "The text at the specified index is cleaned (extra spaces removed) and then tokenized using the provided tokenizer. The encode_plus method of the tokenizer is used to perform tokenization, which also generates the necessary attention mask and token type IDs for the text.\n",
        "The method applies padding to ensure the tokenized text has a uniform length (max_len) and truncates texts that exceed this length.\n",
        "The token type IDs are included for models that require them, but if not provided by the tokenizer, a default list of zeros is used.\n",
        "The method returns a dictionary with the tokenized input (ids), the attention mask (mask), token type IDs (token_type_ids), and the sentiment label (targets) for the given index. Each item in the dictionary is converted to a PyTorch tensor with the appropriate data type (torch.long).\n",
        "This class is tailored for sentiment analysis, converting raw text and labels from a dataframe into a format suitable for training transformer-based models, such as BERT or RoBERTa, on sentiment classification tasks."
      ],
      "id": "UvEkM0KrW-XK"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c0e1d454"
      },
      "outputs": [],
      "source": [
        "# Defining some key variables that will be used later on in the training\n",
        "MAX_LEN = 256\n",
        "TRAIN_BATCH_SIZE = 8\n",
        "VALID_BATCH_SIZE = 4\n",
        "# EPOCHS = 1\n",
        "LEARNING_RATE = 1e-05 # increase learning rate from 1e-05\n",
        "tokenizer = RobertaTokenizer.from_pretrained('roberta-base', truncation=True, do_lower_case=True)"
      ],
      "id": "c0e1d454"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec4266dd"
      },
      "outputs": [],
      "source": [
        "class SentimentData(Dataset):\n",
        "    def __init__(self, dataframe, tokenizer, max_len=MAX_LEN):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.data = dataframe\n",
        "        self.text = dataframe.phrase\n",
        "        # Ensure targets are integers for CrossEntropyLoss compatibility\n",
        "        self.targets = dataframe.sentiment.astype(int)  # Changed from float to int\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.text)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        text = str(self.text[index])\n",
        "        text = \" \".join(text.split())\n",
        "\n",
        "        \"\"\" tokenize preparing text data for input into\n",
        "        a transformer-based model RoBERTa\"\"\"\n",
        "\n",
        "        inputs = self.tokenizer.encode_plus(\n",
        "            text,\n",
        "            None,\n",
        "            add_special_tokens=True,\n",
        "            max_length=self.max_len,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_token_type_ids=True\n",
        "        )\n",
        "        ids = inputs['input_ids']\n",
        "        mask = inputs['attention_mask']\n",
        "        token_type_ids = inputs.get(\"token_type_ids\", [0] * len(ids))\n",
        "\n",
        "        return {\n",
        "            'ids': torch.tensor(ids, dtype=torch.long),\n",
        "            'mask': torch.tensor(mask, dtype=torch.long),\n",
        "            'token_type_ids': torch.tensor(token_type_ids, dtype=torch.long),\n",
        "            'targets': torch.tensor(self.targets[index], dtype=torch.long)\n",
        "        }\n"
      ],
      "id": "ec4266dd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18d91d71",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "20cdcb54-d449-4406-a80d-55d3971a9b01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TRAIN Dataset: (35738, 2)\n",
            "TEST Dataset: (3880, 2)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "train_data = train\n",
        "test_data=test\n",
        "\n",
        "print(\"TRAIN Dataset: {}\".format(train_data.shape))\n",
        "print(\"TEST Dataset: {}\".format(test_data.shape))\n",
        "\n",
        "training_set = SentimentData(train_data, tokenizer, MAX_LEN)\n",
        "testing_set = SentimentData(test_data, tokenizer, MAX_LEN)"
      ],
      "id": "18d91d71"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "66ff360a"
      },
      "outputs": [],
      "source": [
        "train_params = {'batch_size': TRAIN_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "test_params = {'batch_size': VALID_BATCH_SIZE,\n",
        "                'shuffle': True,\n",
        "                'num_workers': 0\n",
        "                }\n",
        "\n",
        "training_loader = DataLoader(training_set, **train_params)\n",
        "testing_loader = DataLoader(testing_set, **test_params)"
      ],
      "id": "66ff360a"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "99d0d612"
      },
      "source": [
        "## 4 Creating the Neural Network for Fine Tuning"
      ],
      "id": "99d0d612"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c9lQLZuMgU07"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import RobertaModel, RobertaConfig\n",
        "\n",
        "class RobertaClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RobertaClass, self).__init__()\n",
        "        config = RobertaConfig.from_pretrained(\"roberta-base\")\n",
        "        self.roberta = RobertaModel.from_pretrained(\"roberta-base\", config=config)\n",
        "\n",
        "        # Adjusted the classifier head dimensions\n",
        "        self.pre_classifier = torch.nn.Linear(config.hidden_size, 512)  # Reduced layer size\n",
        "        self.dropout = torch.nn.Dropout(0.1)  # Increased dropout rate to prevent overfitting\n",
        "        self.classifier = torch.nn.Linear(512, 2)  # Adjusted for binary classification\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        # Extract outputs from the transformer\n",
        "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "\n",
        "        # Use the representation of the first token ([CLS]) for classification\n",
        "        cls_token_state = outputs[0][:, 0, :]\n",
        "\n",
        "        # Process through the pre-classifier and classifier layers\n",
        "        x = self.pre_classifier(cls_token_state)\n",
        "        x = torch.nn.ReLU()(x)\n",
        "        x = self.dropout(x)\n",
        "        logits = self.classifier(x)\n",
        "\n",
        "        return logits\n"
      ],
      "id": "c9lQLZuMgU07"
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"class RobertaClass(torch.nn.Module):\n",
        "    def __init__(self):\n",
        "        super(RobertaClass, self).__init__()\n",
        "        config = RobertaConfig.from_pretrained(\"roberta-base\")\n",
        "        self.roberta = RobertaModel.from_pretrained(\"roberta-base\")\n",
        "\n",
        "        # Simplified architecture\n",
        "        self.classifier = torch.nn.Linear(config.hidden_size, 2)  # Directly to classification\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.roberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_token_state = outputs[0][:, 0, :]  # Use the [CLS] token's representation\n",
        "\n",
        "        # Directly classify from [CLS] token without additional layers\n",
        "        logits = self.classifier(cls_token_state)\n",
        "\n",
        "        return logits\"\"\"\n"
      ],
      "metadata": {
        "id": "SIVH-Joh_R9G"
      },
      "id": "SIVH-Joh_R9G",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4beebeaf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "27eb57d9-701b-413d-e483-17fddd4e8c32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaClass(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): RobertaEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0-11): 12 x RobertaLayer(\n",
              "          (attention): RobertaAttention(\n",
              "            (self): RobertaSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): RobertaSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): RobertaIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "            (intermediate_act_fn): GELUActivation()\n",
              "          )\n",
              "          (output): RobertaOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): RobertaPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (pre_classifier): Linear(in_features=768, out_features=512, bias=True)\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=512, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 176
        }
      ],
      "source": [
        "model = RobertaClass()\n",
        "model.to(device)"
      ],
      "id": "4beebeaf"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "af83de94"
      },
      "outputs": [],
      "source": [
        "# 5. Fine tune the model\n",
        "\n",
        "# Creating the loss function and optimizer\n",
        "loss_function = torch.nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params =  model.parameters(), lr=LEARNING_RATE)"
      ],
      "id": "af83de94"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_jjOFZOEjdW4"
      },
      "outputs": [],
      "source": [
        "def calculate_accuracy(preds, targets):\n",
        "    # Assuming preds and targets are tensors. Converts predictions to the same shape as targets, if necessary.\n",
        "    if preds.shape != targets.shape:\n",
        "        preds = preds.argmax(dim=1)\n",
        "\n",
        "    # Calculate the number of correctly predicted examples.\n",
        "    n_correct = (preds == targets).sum().item()\n",
        "\n",
        "    # Calculate the accuracy: correct predictions / total examples\n",
        "    accuracy = n_correct / targets.size(0)  # Assuming targets is a tensor that has the total number of examples as its size.\n",
        "\n",
        "    return accuracy"
      ],
      "id": "_jjOFZOEjdW4"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3MTNfVHlH6n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "# Sample predictions and targets for testing\n",
        "preds = torch.tensor([[0.2, 0.8], [0.9, 0.1]], device='cuda:0')  # Example predictions on a CUDA device\n",
        "targets = torch.tensor([1, 0], device='cuda:0')  # Corresponding targets on the same CUDA device\n"
      ],
      "id": "t3MTNfVHlH6n"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EUTZaPEGj1f5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "250637d9-f03f-4478-c65d-3b1c8ea6148d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda:0 cuda:0\n"
          ]
        }
      ],
      "source": [
        "print(preds.device, targets.device)"
      ],
      "id": "EUTZaPEGj1f5"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_g86I7YqkJJu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "892dfac3-1d08-41be-b72a-fd738e2fa57b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2, 2]) torch.Size([2])\n"
          ]
        }
      ],
      "source": [
        "print(preds.shape, targets.shape)"
      ],
      "id": "_g86I7YqkJJu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qqFxHz_-lmH1"
      },
      "outputs": [],
      "source": [
        "model = model.to('cuda:0')  # Move model to the same device as your tensors"
      ],
      "id": "qqFxHz_-lmH1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2370e4ce"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def train(epoch):\n",
        "    tr_loss = 0\n",
        "    n_correct = 0\n",
        "    nb_tr_steps = 0\n",
        "    nb_tr_examples = 0\n",
        "    model.train()\n",
        "    for _, data in tqdm(enumerate(training_loader, 0)):\n",
        "        ids = data['ids'].to(device, dtype=torch.long)\n",
        "        mask = data['mask'].to(device, dtype=torch.long)\n",
        "        token_type_ids = data['token_type_ids'].to(device, dtype=torch.long)\n",
        "        targets = data['targets'].to(device, dtype=torch.long)  # Ensure targets are class indices\n",
        "        outputs = model(ids, attention_mask=mask, token_type_ids=token_type_ids)[0]  # Adjust based on your model's output\n",
        "        loss = loss_function(outputs, targets)\n",
        "        tr_loss += loss.item()\n",
        "        big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "        n_correct += (big_idx == targets).sum().item()\n",
        "\n",
        "        nb_tr_steps += 1\n",
        "        nb_tr_examples += targets.size(0)\n",
        "\n",
        "        if _ % 5000 == 0:\n",
        "            loss_step = tr_loss / nb_tr_steps\n",
        "            accu_step = (n_correct * 100) / nb_tr_examples\n",
        "            print(f\"Training Loss per 5000 steps: {loss_step}\")\n",
        "            print(f\"Training Accuracy per 5000 steps: {accu_step}\")\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        print(f'The Total Accuracy for Epoch {epoch}: {(n_correct * 100) / nb_tr_examples}')\n",
        "        epoch_loss = tr_loss / nb_tr_steps\n",
        "        epoch_accu = (n_correct * 100) / nb_tr_examples\n",
        "        print(f\"Training Loss Epoch: {epoch_loss}\")\n",
        "        print(f\"Training Accuracy Epoch: {epoch_accu}\")\n",
        "\n"
      ],
      "id": "2370e4ce"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUChyEQDnuvc"
      },
      "outputs": [],
      "source": [
        "# Issue with n_correct variable is defined inside a function or loop and I'm\n",
        "# trying to access it outside that scope, or if the code that defines the variable hasn't been executed before the print statement."
      ],
      "id": "yUChyEQDnuvc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tyI--2tQmwPw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9452987-7f56-43a4-cebe-57affc002204"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The Total Accuracy for Epoch 1: 100.0\n"
          ]
        }
      ],
      "source": [
        "def train(epoch):\n",
        "    n_correct = 0\n",
        "    nb_tr_examples = 0\n",
        "    model.train()  # Set your model to training mode\n",
        "\n",
        "    for _, data in enumerate(training_loader):\n",
        "        # Your data loading and model forward pass logic here\n",
        "        # For example: outputs = model(inputs)\n",
        "\n",
        "        # Example update of 'n_correct' and 'nb_tr_examples'\n",
        "        # Here, 'outputs' would be your model predictions, and 'labels' your ground truth\n",
        "        # preds = outputs.argmax(dim=1)  # Assuming outputs are raw logits\n",
        "\n",
        "        # Dummy values for demonstration; replace with your actual logic\n",
        "        preds = torch.tensor([0, 1])  # Example predictions\n",
        "        labels = torch.tensor([0, 1])  # Example ground truth\n",
        "\n",
        "        n_correct += (preds == labels).sum().item()\n",
        "        nb_tr_examples += labels.size(0)\n",
        "\n",
        "    # Now 'n_correct' and 'nb_tr_examples' are defined and can be used\n",
        "    print(f'The Total Accuracy for Epoch {epoch}: {(n_correct * 100) / nb_tr_examples}')\n",
        "\n",
        "# Example call to the train function\n",
        "train(epoch=1)\n"
      ],
      "id": "tyI--2tQmwPw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "999957bc"
      },
      "outputs": [],
      "source": [
        "# 6. Validating the model"
      ],
      "id": "999957bc"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "37a5cffe"
      },
      "outputs": [],
      "source": [
        "def valid(model, testing_loader):\n",
        "    model.eval()\n",
        "    n_correct = 0; n_wrong = 0; total = 0; tr_loss = 0; nb_tr_steps = 0; nb_tr_examples = 0\n",
        "    with torch.no_grad():\n",
        "        for _, data in tqdm(enumerate(testing_loader, 0)):\n",
        "            ids = data['ids'].to(device, dtype=torch.long)\n",
        "            mask = data['mask'].to(device, dtype=torch.long)\n",
        "            # Removed token_type_ids from the data loading as it's not used in the model's forward method\n",
        "            targets = data['targets'].to(device, dtype=torch.long)\n",
        "            outputs = model(ids, mask).squeeze()  # Adjusted the model call here\n",
        "            loss = loss_function(outputs, targets)\n",
        "            tr_loss += loss.item()\n",
        "            big_val, big_idx = torch.max(outputs.data, dim=1)\n",
        "            n_correct += (big_idx == targets).sum().item()\n",
        "\n",
        "            nb_tr_steps += 1\n",
        "            nb_tr_examples += targets.size(0)\n",
        "\n",
        "            if _ % 5000 == 0:\n",
        "                loss_step = tr_loss / nb_tr_steps\n",
        "                accu_step = (n_correct * 100) / nb_tr_examples\n",
        "                print(f\"Validation Loss per 100 steps: {loss_step}\")\n",
        "                print(f\"Validation Accuracy per 100 steps: {accu_step}\")\n",
        "\n",
        "    epoch_loss = tr_loss / nb_tr_steps\n",
        "    epoch_accu = (n_correct * 100) / nb_tr_examples\n",
        "    print(f\"Validation Loss Epoch: {epoch_loss}\")\n",
        "    print(f\"Validation Accuracy Epoch: {epoch_accu}\")\n",
        "\n",
        "    return epoch_accu\n"
      ],
      "id": "37a5cffe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1a4ba346",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8126238-ee10-4924-ac7d-a3c7f626af7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "9it [00:00, 40.13it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss per 100 steps: 0.6944535970687866\n",
            "Validation Accuracy per 100 steps: 50.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "970it [00:22, 43.46it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation Loss Epoch: 0.6963292408849775\n",
            "Validation Accuracy Epoch: 48.42783505154639\n",
            "Accuracy on test data = 48.43%\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "acc = valid(model, testing_loader)\n",
        "print(\"Accuracy on test data = %0.2f%%\" % acc)"
      ],
      "id": "1a4ba346"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90c3a4a1"
      },
      "outputs": [],
      "source": [
        "# 7. Saving the Trained Model Artifacts for inference"
      ],
      "id": "90c3a4a1"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "56bf38ba"
      },
      "outputs": [],
      "source": [
        "output_model_file = 'pytorch_roberta_sentiment.bin'\n",
        "output_vocab_file = './'\n",
        "\n",
        "model_to_save = model\n",
        "torch.save(model_to_save, output_model_file)\n",
        "tokenizer.save_vocabulary(output_vocab_file)\n",
        "\n",
        "print('All files saved')\n"
      ],
      "id": "56bf38ba"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e060fe4e"
      },
      "outputs": [],
      "source": [],
      "id": "e060fe4e"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7264a061"
      },
      "outputs": [],
      "source": [],
      "id": "7264a061"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "abe55f8d"
      },
      "outputs": [],
      "source": [],
      "id": "abe55f8d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fc13bac"
      },
      "outputs": [],
      "source": [],
      "id": "5fc13bac"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ec29bd67"
      },
      "outputs": [],
      "source": [],
      "id": "ec29bd67"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4bf203bf"
      },
      "outputs": [],
      "source": [],
      "id": "4bf203bf"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}